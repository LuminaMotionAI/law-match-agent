import streamlit as st
import pandas as pd
import json
import os
import warnings
from datetime import datetime
from typing import List, Dict, Optional

# ê²½ê³  ë©”ì‹œì§€ ì–µì œ
warnings.filterwarnings("ignore")
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# ê°€ë²¼ìš´ ë²„ì „ìš© ì„í¬íŠ¸
from api.huggingface_api import HuggingFaceAPI

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="âš–ï¸ í•œêµ­ ë²•ë¥  íŒë¡€ ê²€ìƒ‰ AI",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì „ì—­ ë³€ìˆ˜
@st.cache_resource
def init_huggingface_api():
    """í—ˆê¹…í˜ì´ìŠ¤ API ì´ˆê¸°í™” (ë¡œì»¬ ë°±ì—… í¬í•¨)"""
    try:
        st.sidebar.write("ğŸ”„ AI ëª¨ë¸ ë¡œë”© ì¤‘...")
        hf_api = HuggingFaceAPI()  # ë¡œì»¬ ë°ì´í„°ì…‹ ìë™ ì‚¬ìš©
        st.sidebar.success("âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        return hf_api
    except Exception as e:
        st.sidebar.error(f"ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return None

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    # íƒ€ì´í‹€
    st.title("âš–ï¸ í•œêµ­ ë²•ë¥  íŒë¡€ ê²€ìƒ‰ AI")
    st.markdown("### 80,000ê°œ í•œêµ­ì–´ ë²•ë¥  ë°ì´í„° ê¸°ë°˜ ì§€ëŠ¥í˜• ê²€ìƒ‰")
    st.markdown("---")
    
    # API ì´ˆê¸°í™”
    hf_api = init_huggingface_api()
    
    if not hf_api:
        st.error("âŒ AI ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        st.info("ğŸ’¡ ë¬¸ì œê°€ ì§€ì†ë˜ë©´ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”.")
        return
    
    # ì‚¬ì´ë“œë°” ë©”ë‰´
    with st.sidebar:
        st.header("ğŸ”§ ë©”ë‰´")
        menu = st.radio(
            "ê¸°ëŠ¥ ì„ íƒ",
            ["ğŸ  í™ˆ", "ğŸ” ì‚¬ë¡€ ê²€ìƒ‰", "ğŸš€ ì¢…í•© ë¶„ì„", "â“ ë²•ë¥  Q&A", "ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´"]
        )
        
        st.markdown("---")
        
        # ë°ì´í„°ì…‹ ì •ë³´
        st.subheader("ğŸ“Š ë°ì´í„°ì…‹")
        dataset_info = hf_api.get_dataset_info()
        if dataset_info:
            st.metric("ì „ì²´ ë°ì´í„°", f"{dataset_info['total_count']:,}ê°œ")
            
            # ë°ì´í„° íƒ€ì…ë³„ í†µê³„
            with st.expander("ğŸ“‹ ë°ì´í„° êµ¬ì„±"):
                for data_type, count in dataset_info['data_types'].items():
                    st.write(f"â€¢ {data_type}: {count:,}ê°œ")
        
        st.markdown("---")
        st.info("ğŸ¤– AI ê¸°ë°˜ í•œêµ­ì–´ ë²•ë¥  ê²€ìƒ‰")
    
    # ë©”ì¸ ì»¨í…ì¸ 
    if menu == "ğŸ  í™ˆ":
        show_home(hf_api)
    elif menu == "ğŸ” ì‚¬ë¡€ ê²€ìƒ‰":
        show_case_search(hf_api)
    elif menu == "ğŸš€ ì¢…í•© ë¶„ì„":
        show_comprehensive_analysis(hf_api)
    elif menu == "â“ ë²•ë¥  Q&A":
        show_legal_qa(hf_api)
    elif menu == "ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´":
        show_dataset_info(hf_api)

def show_home(hf_api):
    """í™ˆ í˜ì´ì§€"""
    st.header("ğŸ  í•œêµ­ ë²•ë¥  íŒë¡€ ê²€ìƒ‰ AI")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ” ì£¼ìš” ê¸°ëŠ¥")
        st.markdown("""
        - **ğŸ” ì‚¬ë¡€ ê²€ìƒ‰**: AI ê¸°ë°˜ ìœ ì‚¬ íŒë¡€ ì°¾ê¸°
        - **ğŸš€ ì¢…í•© ë¶„ì„**: ì‚¬ê±´ ë¶„ë¥˜ ë° ê´€ë ¨ ë²•ë ¹ ê²€ìƒ‰
        - **â“ ë²•ë¥  Q&A**: ë²•ë¥  í•´ì„ ë° ì§ˆì˜ì‘ë‹µ
        - **ğŸ“Š ë°ì´í„° ë¶„ì„**: 80,000ê°œ ë²•ë¥  ë°ì´í„° í™œìš©
        """)
        
        st.subheader("ğŸ¯ íŠ¹ì§•")
        st.markdown("""
        - âœ… **80,000ê°œ** í•œêµ­ì–´ ë²•ë¥  ë°ì´í„°
        - âœ… **AI ì„ë² ë”©** ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
        - âœ… **ì‹¤ì‹œê°„ ê²€ìƒ‰** (ë¹ ë¥¸ ì‘ë‹µ)
        - âœ… **ë‹¤ì–‘í•œ ë²•ë¥  ë¶„ì•¼** ì»¤ë²„
        """)
    
    with col2:
        st.subheader("ğŸ“Š ë°ì´í„°ì…‹ êµ¬ì„±")
        
        dataset_info = hf_api.get_dataset_info()
        if dataset_info:
            # ë°ì´í„° íƒ€ì…ë³„ íŒŒì´ ì°¨íŠ¸ (ê°„ë‹¨ ë²„ì „)
            data_types = dataset_info['data_types']
            
            for data_type, count in data_types.items():
                percentage = (count / dataset_info['total_count']) * 100
                st.metric(
                    label=data_type.replace('_', ' '),
                    value=f"{count:,}ê°œ",
                    delta=f"{percentage:.1f}%"
                )
        
        st.subheader("ğŸš€ ë¹ ë¥¸ ì‹œì‘")
        st.markdown("""
        1. **ğŸ” ì‚¬ë¡€ ê²€ìƒ‰** íƒ­ì—ì„œ í‚¤ì›Œë“œ ì…ë ¥
        2. **AIê°€ ìœ ì‚¬ ì‚¬ë¡€** ìë™ ê²€ìƒ‰
        3. **ê²°ê³¼ í™•ì¸** ë° ìƒì„¸ ì •ë³´ ì—´ëŒ
        """)

def show_case_search(hf_api):
    """ì‚¬ë¡€ ê²€ìƒ‰ í˜ì´ì§€"""
    st.header("ğŸ” AI ê¸°ë°˜ ì‚¬ë¡€ ê²€ìƒ‰")
    st.write("ë²•ë¥  ì§ˆë¬¸ì´ë‚˜ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ë©´ AIê°€ ìœ ì‚¬í•œ ì‚¬ë¡€ë¥¼ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤.")
    
    # ê²€ìƒ‰ ì…ë ¥
    search_query = st.text_area(
        "ê²€ìƒ‰í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ: ìŒì£¼ìš´ì „ìœ¼ë¡œ ì¸í•œ êµí†µì‚¬ê³  ì†í•´ë°°ìƒ\nì˜ˆ: ì¸í„°ë„· ëª…ì˜ˆí›¼ì† ì‚¬ê±´\nì˜ˆ: ê³„ì•½ ìœ„ë°˜ì— ë”°ë¥¸ ìœ„ìë£Œ",
        height=100
    )
    
    # ê²€ìƒ‰ ì˜µì…˜
    col1, col2, col3 = st.columns(3)
    
    with col1:
        case_type = st.selectbox(
            "ì‚¬ê±´ ìœ í˜• í•„í„°:",
            ["ì „ì²´", "í•´ì„ë¡€", "íŒê²°ë¬¸", "ê²°ì •ë¡€", "ë²•ë ¹"]
        )
    
    with col2:
        num_results = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 1, 20, 5)
    
    with col3:
        search_button = st.button("ğŸ” ê²€ìƒ‰ ì‹¤í–‰", type="primary")
    
    # ê²€ìƒ‰ ì‹¤í–‰
    if search_button and search_query.strip():
        with st.spinner("AIê°€ ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ê²€ìƒ‰ ì‹¤í–‰
                search_type = None if case_type == "ì „ì²´" else case_type
                results = hf_api.search_similar_cases(
                    search_query, 
                    top_k=num_results,
                    case_type=search_type
                )
                
                if results:
                    st.success(f"âœ… {len(results)}ê°œì˜ ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    
                    # ê²°ê³¼ í‘œì‹œ
                    for i, result in enumerate(results, 1):
                        with st.expander(
                            f"ğŸ›ï¸ ì‚¬ë¡€ {i} - {result['case_type']} "
                            f"(ìœ ì‚¬ë„: {result['similarity_score']:.3f})"
                        ):
                            # ê¸°ë³¸ ì •ë³´
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.write(f"**ì‚¬ê±´ë²ˆí˜¸:** {result['case_number']}")
                                st.write(f"**ì‚¬ê±´ëª…:** {result['case_name']}")
                                st.write(f"**ë²•ì›:** {result['court_code']}")
                            
                            with col2:
                                st.write(f"**ë‚ ì§œ:** {result['final_date']}")
                                st.write(f"**ì‚¬ê±´ ìœ í˜•:** {result['case_type']}")
                                st.metric("ìœ ì‚¬ë„", f"{result['similarity_score']:.3f}")
                            
                            # ë‚´ìš©
                            if result.get('query'):
                                st.markdown("**ğŸ“‹ ì§ˆì˜/ì œëª©:**")
                                st.write(result['query'])
                            
                            if result.get('answer'):
                                st.markdown("**âš–ï¸ ë‹µë³€/íŒì‹œì‚¬í•­:**")
                                st.write(result['answer'])
                            
                            # ì¶”ê°€ ì •ë³´
                            if result.get('instruction'):
                                with st.expander("ğŸ“– ì¶”ê°€ ì •ë³´"):
                                    st.write(f"**ì§€ì‹œì‚¬í•­:** {result['instruction']}")
                                    st.write(f"**ì¶œì²˜:** {result['source']}")
                
                else:
                    st.warning("âš ï¸ ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    st.info("ğŸ’¡ ë‹¤ë¥¸ í‚¤ì›Œë“œë‚˜ ë” ì¼ë°˜ì ì¸ ìš©ì–´ë¡œ ë‹¤ì‹œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.")
                
            except Exception as e:
                st.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    
    elif search_button and not search_query.strip():
        st.warning("âš ï¸ ê²€ìƒ‰í•  ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def show_comprehensive_analysis(hf_api):
    """ì¢…í•© ë¶„ì„ í˜ì´ì§€"""
    st.header("ğŸš€ AI ê¸°ë°˜ ì¢…í•© ì‚¬ê±´ ë¶„ì„")
    st.write("ì‚¬ê±´ ë‚´ìš©ì„ ì…ë ¥í•˜ë©´ AIê°€ ë¶„ë¥˜, ìœ ì‚¬ íŒë¡€, ê´€ë ¨ ë²•ë ¹ì„ ì¢…í•© ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # ì‚¬ê±´ ì…ë ¥
    case_input = st.text_area(
        "ì‚¬ê±´ ë‚´ìš©ì„ ìì„¸íˆ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ: í”¼ê³ ì¸ì´ ì˜¨ë¼ì¸ ì‡¼í•‘ëª°ì—ì„œ ê°€ì§œ ëª…í’ˆì„ íŒë§¤í•˜ì—¬ ì†Œë¹„ìë“¤ì—ê²Œ ì´ 500ë§Œì›ì˜ í”¼í•´ë¥¼ ì…íŒ ì‚¬ê¸° ì‚¬ê±´ì…ë‹ˆë‹¤...",
        height=150
    )
    
    if st.button("ğŸ” ì¢…í•© ë¶„ì„ ì‹œì‘", type="primary"):
        if not case_input.strip():
            st.error("ì‚¬ê±´ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        with st.spinner("AIê°€ ì¢…í•© ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ì¢…í•© ë¶„ì„ ì‹¤í–‰
                analysis_result = hf_api.get_enhanced_case_analysis(case_input)
                
                if 'error' in analysis_result:
                    st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {analysis_result['error']}")
                    return
                
                # ê²°ê³¼ í‘œì‹œ
                st.success("âœ… ì¢…í•© ë¶„ì„ ì™„ë£Œ!")
                
                # 1. ì‚¬ê±´ ë¶„ë¥˜
                st.subheader("ğŸ“‹ ì‚¬ê±´ ë¶„ë¥˜")
                classification = analysis_result.get('case_classification', 'Unknown')
                st.info(f"ë¶„ë¥˜ ê²°ê³¼: **{classification}**")
                
                # 2. ìœ ì‚¬ íŒë¡€
                similar_precedents = analysis_result.get('similar_precedents', [])
                if similar_precedents:
                    st.subheader("âš–ï¸ ìœ ì‚¬ íŒë¡€")
                    
                    for i, case in enumerate(similar_precedents[:3], 1):
                        with st.expander(f"íŒë¡€ {i} - ìœ ì‚¬ë„: {case.get('similarity_score', 0):.3f}"):
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.write(f"**ì‚¬ê±´ë²ˆí˜¸:** {case.get('case_number', 'N/A')}")
                                st.write(f"**ì‚¬ê±´ëª…:** {case.get('case_name', 'N/A')}")
                                st.write(f"**ë²•ì›:** {case.get('court_code', 'N/A')}")
                            
                            with col2:
                                st.write(f"**ë‚ ì§œ:** {case.get('final_date', 'N/A')}")
                                st.write(f"**ì‚¬ê±´ ìœ í˜•:** {case.get('case_type', 'Unknown')}")
                                st.metric("ìœ ì‚¬ë„", f"{case.get('similarity_score', 0):.3f}")
                            
                            if case.get('query'):
                                st.write(f"**ì§ˆì˜:** {case['query']}")
                            
                            if case.get('answer'):
                                st.write(f"**ë‹µë³€:** {case['answer']}")
                
                # 3. ê´€ë ¨ ë²•ë ¹
                applicable_laws = analysis_result.get('applicable_laws', [])
                if applicable_laws:
                    st.subheader("ğŸ“œ ê´€ë ¨ ë²•ë ¹")
                    
                    for law in applicable_laws[:3]:
                        with st.expander(f"ë²•ë ¹ {law.get('case_name', 'ë²•ë ¹')}"):
                            st.write(f"**ì§ˆì˜:** {law.get('query', '')}")
                            st.write(f"**ë‹µë³€:** {law.get('answer', '')}")
                            st.write(f"**ìœ ì‚¬ë„:** {law.get('similarity_score', 0):.3f}")
                
                # 4. ë²•ë¥  í•´ì„
                interpretations = analysis_result.get('legal_interpretations', [])
                if interpretations:
                    st.subheader("ğŸ” ë²•ë¥  í•´ì„")
                    
                    for interp in interpretations:
                        with st.expander(f"í•´ì„ë¡€ - ìœ ì‚¬ë„: {interp.get('similarity_score', 0):.3f}"):
                            st.write(f"**ì§ˆì˜:** {interp.get('query', '')}")
                            st.write(f"**í•´ì„:** {interp.get('answer', '')}")
                
                # 5. ê¶Œê³ ì‚¬í•­
                recommendations = analysis_result.get('recommendations', [])
                if recommendations:
                    st.subheader("ğŸ’¡ ê¶Œê³ ì‚¬í•­")
                    
                    for i, rec in enumerate(recommendations, 1):
                        st.write(f"{i}. {rec}")
                
            except Exception as e:
                st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

def show_legal_qa(hf_api):
    """ë²•ë¥  Q&A í˜ì´ì§€"""
    st.header("â“ AI ë²•ë¥  ì§ˆì˜ì‘ë‹µ")
    st.write("ë²•ë¥  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì‹œë©´ ê´€ë ¨ í•´ì„ë¡€ì™€ íŒë¡€ë¥¼ ì°¾ì•„ì„œ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")
    
    # ì§ˆë¬¸ ì…ë ¥
    legal_question = st.text_area(
        "ë²•ë¥  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ì˜ˆ: ì„ëŒ€ì°¨ ê³„ì•½ì—ì„œ ë³´ì¦ê¸ˆ ë°˜í™˜ ì˜ë¬´ëŠ” ì–¸ì œê¹Œì§€ì¸ê°€ìš”?\nì˜ˆ: êµí†µì‚¬ê³ ì—ì„œ ê³¼ì‹¤ë¹„ìœ¨ì€ ì–´ë–»ê²Œ ê²°ì •ë˜ë‚˜ìš”?",
        height=100
    )
    
    if st.button("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°", type="primary"):
        if not legal_question.strip():
            st.error("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        with st.spinner("AIê°€ ë²•ë¥  ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ë²•ë¥  í•´ì„ ê²€ìƒ‰
                interpretation = hf_api.get_legal_interpretation(legal_question)
                
                if interpretation.get('answer'):
                    st.success("âœ… ê´€ë ¨ ë²•ë¥  í•´ì„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    
                    # ë‹µë³€ í‘œì‹œ
                    st.subheader("ğŸ“‹ ì§ˆë¬¸")
                    st.info(interpretation.get('question', legal_question))
                    
                    st.subheader("âš–ï¸ ë²•ë¥  í•´ì„")
                    st.write(interpretation.get('answer', ''))
                    
                    # ì¶”ê°€ ì •ë³´
                    if interpretation.get('context'):
                        with st.expander("ğŸ“š ê´€ë ¨ ì •ë³´"):
                            st.write(interpretation['context'])
                    
                    # ì‹ ë¢°ë„ ì •ë³´
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.metric(
                            "ìœ ì‚¬ë„", 
                            f"{interpretation.get('similarity_score', 0):.3f}"
                        )
                    
                    with col2:
                        st.info(f"ì¶œì²˜: {interpretation.get('source', 'Unknown')}")
                
                else:
                    st.warning("ì •í™•í•œ ë²•ë¥  í•´ì„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    
                    # ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
                    st.subheader("ğŸ” ê´€ë ¨ ì‚¬ë¡€ ê²€ìƒ‰")
                    results = hf_api.search_similar_cases(legal_question, top_k=3)
                    
                    if results:
                        for i, result in enumerate(results, 1):
                            with st.expander(f"ê´€ë ¨ ì‚¬ë¡€ {i} - ìœ ì‚¬ë„: {result['similarity_score']:.3f}"):
                                st.write(f"**ì§ˆì˜:** {result['query']}")
                                st.write(f"**ë‹µë³€:** {result['answer']}")
                                st.write(f"**ì‚¬ê±´:** {result['case_name']}")
                    else:
                        st.info("ê´€ë ¨ ì‚¬ë¡€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")
                
            except Exception as e:
                st.error(f"ì§ˆì˜ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

def show_dataset_info(hf_api):
    """ë°ì´í„°ì…‹ ì •ë³´ í˜ì´ì§€"""
    st.header("ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´")
    
    dataset_info = hf_api.get_dataset_info()
    
    if not dataset_info:
        st.error("ë°ì´í„°ì…‹ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì „ì²´ í†µê³„
    st.subheader("ğŸ“ˆ ì „ì²´ í†µê³„")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ì „ì²´ ë°ì´í„°", f"{dataset_info['total_count']:,}ê°œ")
    
    with col2:
        st.metric("ë°ì´í„° íƒ€ì…", f"{len(dataset_info['data_types'])}ì¢…ë¥˜")
    
    with col3:
        st.metric("ê¸°ê°„", f"{dataset_info['date_range']['earliest']} ~ {dataset_info['date_range']['latest']}")
    
    # ë°ì´í„° íƒ€ì…ë³„ ë¶„í¬
    st.subheader("ğŸ“Š ë°ì´í„° íƒ€ì…ë³„ ë¶„í¬")
    
    data_types = dataset_info['data_types']
    
    # í…Œì´ë¸” í˜•íƒœë¡œ í‘œì‹œ
    df_display = pd.DataFrame([
        {
            'ë°ì´í„° íƒ€ì…': data_type,
            'ê°œìˆ˜': f"{count:,}ê°œ",
            'ë¹„ìœ¨': f"{(count/dataset_info['total_count']*100):.1f}%"
        }
        for data_type, count in data_types.items()
    ])
    
    st.dataframe(df_display, use_container_width=True)
    
    # ë°ì´í„° ì„¤ëª…
    st.subheader("ğŸ“‹ ë°ì´í„° ì„¤ëª…")
    
    descriptions = {
        'ê²°ì •ë¡€_QA': 'í—Œë²•ì¬íŒì†Œ ê²°ì •ë¡€ ì§ˆì˜ì‘ë‹µ ë°ì´í„°',
        'ê²°ì •ë¡€_SUM': 'í—Œë²•ì¬íŒì†Œ ê²°ì •ë¡€ ìš”ì•½ ë°ì´í„°',
        'ë²•ë ¹_QA': 'ë²•ë ¹ ì¡°ë¬¸ ì§ˆì˜ì‘ë‹µ ë°ì´í„°',
        'íŒê²°ë¬¸_QA': 'ë²•ì› íŒê²°ë¬¸ ì§ˆì˜ì‘ë‹µ ë°ì´í„°',
        'íŒê²°ë¬¸_SUM': 'ë²•ì› íŒê²°ë¬¸ ìš”ì•½ ë°ì´í„°',
        'í•´ì„ë¡€_QA': 'ë²•ë ¹ í•´ì„ë¡€ ì§ˆì˜ì‘ë‹µ ë°ì´í„°',
        'í•´ì„ë¡€_SUM': 'ë²•ë ¹ í•´ì„ë¡€ ìš”ì•½ ë°ì´í„°'
    }
    
    for data_type, count in data_types.items():
        description = descriptions.get(data_type, 'ì„¤ëª… ì—†ìŒ')
        st.write(f"â€¢ **{data_type}** ({count:,}ê°œ): {description}")
    
    # ê¸°ìˆ  ì •ë³´
    st.subheader("ğŸ”§ ê¸°ìˆ  ì •ë³´")
    
    st.write(f"â€¢ **ë°ì´í„° ì†ŒìŠ¤**: {dataset_info['source']}")
    st.write("â€¢ **ì„ë² ë”© ëª¨ë¸**: snunlp/KR-SBERT-V40K-klueNLI")
    st.write("â€¢ **ê²€ìƒ‰ ë°©ì‹**: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰")
    st.write("â€¢ **ì§€ì› ì–¸ì–´**: í•œêµ­ì–´")

if __name__ == "__main__":
    main() 