import streamlit as st
import pandas as pd
import json
import os
import warnings
from datetime import datetime
from typing import List, Dict, Optional

# ê²½ê³  ë©”ì‹œì§€ ì–µì œ
warnings.filterwarnings("ignore")
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# ê°€ë²¼ìš´ ë²„ì „ìš© ì„í¬íŠ¸
from api.huggingface_api import HuggingFaceAPI

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="âš–ï¸ í•œêµ­ ë²•ë¥  íŒë¡€ ê²€ìƒ‰ AI",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì „ì—­ ë³€ìˆ˜
@st.cache_resource
def init_huggingface_api():
    """í—ˆê¹…í˜ì´ìŠ¤ API ì´ˆê¸°í™”"""
    try:
        st.sidebar.write("ğŸ”„ í—ˆê¹…í˜ì´ìŠ¤ ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
        hf_api = HuggingFaceAPI()
        
        # ë°ì´í„°ì…‹ ë¡œë“œ ìƒíƒœ í™•ì¸
        if hf_api.df.empty:
            st.sidebar.error("âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨")
            return None
        else:
            st.sidebar.success(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ: {len(hf_api.df):,}ê°œ ë°ì´í„°")
            return hf_api
            
    except Exception as e:
        st.sidebar.error(f"âŒ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return None

def show_dataset_info(hf_api):
    """ë°ì´í„°ì…‹ ì •ë³´ í‘œì‹œ"""
    if hf_api is None:
        st.error("ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.info("ğŸ’¡ **í•´ê²° ë°©ë²•:**")
        st.markdown("""
        1. **Streamlit Cloud Secrets ì„¤ì • í™•ì¸**
        2. **í—ˆê¹…í˜ì´ìŠ¤ í† í° ìœ íš¨ì„± í™•ì¸**
        3. **ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìƒíƒœ í™•ì¸**
        """)
        return
        
    try:
        dataset_info = hf_api.get_dataset_info()
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ğŸ“Š ì´ ë°ì´í„° ìˆ˜", f"{dataset_info['total_count']:,}")
        
        with col2:
            st.metric("ğŸ“ ë°ì´í„° ìœ í˜•", len(dataset_info['data_types']))
            
        with col3:
            st.metric("ğŸŒ ë°ì´í„°ì…‹", dataset_info['source'].split('/')[-1])
        
        # ë°ì´í„° ìœ í˜•ë³„ ë¶„í¬
        st.subheader("ğŸ“ˆ ë°ì´í„° ìœ í˜•ë³„ ë¶„í¬")
        type_counts = pd.DataFrame(list(dataset_info['data_types'].items()), 
                                 columns=['ìœ í˜•', 'ê°œìˆ˜'])
        st.bar_chart(type_counts.set_index('ìœ í˜•'))
        
    except Exception as e:
        st.error(f"âŒ ë°ì´í„°ì…‹ ì •ë³´ í‘œì‹œ ì˜¤ë¥˜: {e}")

def search_legal_cases(hf_api):
    """ë²•ë¥  ì‚¬ë¡€ ê²€ìƒ‰"""
    if hf_api is None:
        st.error("âŒ ê²€ìƒ‰ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    st.subheader("ğŸ” ìœ ì‚¬ íŒë¡€ ê²€ìƒ‰")
    
    # ê²€ìƒ‰ ì…ë ¥
    col1, col2 = st.columns([3, 1])
    
    with col1:
        query = st.text_input("ê²€ìƒ‰í•  ë²•ë¥  ì‚¬ì•ˆì„ ì…ë ¥í•˜ì„¸ìš”:", 
                             placeholder="ì˜ˆ: ìŒì£¼ìš´ì „ìœ¼ë¡œ ì¸í•œ êµí†µì‚¬ê³ ")
    
    with col2:
        case_type = st.selectbox("ì‚¬ë¡€ ìœ í˜•", 
                                ["ì „ì²´", "íŒê²°ë¬¸", "ê²°ì •ë¡€", "í•´ì„ë¡€", "ë²•ë ¹"])
    
    if st.button("ğŸ” ê²€ìƒ‰", type="primary"):
        if query.strip():
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                try:
                    results = hf_api.search_similar_cases(query, top_k=5, case_type=case_type)
                    
                    if results:
                        st.success(f"âœ… {len(results)}ê°œì˜ ìœ ì‚¬ ì‚¬ë¡€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                        
                        for i, result in enumerate(results, 1):
                            with st.expander(f"ğŸ“„ ì‚¬ë¡€ {i} (ìœ ì‚¬ë„: {result['similarity']:.2%})"):
                                st.markdown(f"**ğŸ“‹ ì§ˆë¬¸:** {result['input']}")
                                st.markdown(f"**âš–ï¸ ë‹µë³€:** {result['output']}")
                                st.markdown(f"**ğŸ·ï¸ ìœ í˜•:** {result['data_type']}")
                    else:
                        st.warning("ğŸ” ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”.")
                        
                except Exception as e:
                    st.error(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        else:
            st.warning("âš ï¸ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    # íƒ€ì´í‹€
    st.title("âš–ï¸ í•œêµ­ ë²•ë¥  íŒë¡€ ê²€ìƒ‰ AI")
    st.markdown("### ğŸ¤– í—ˆê¹…í˜ì´ìŠ¤ ê¸°ë°˜ ì§€ëŠ¥í˜• ë²•ë¥  ê²€ìƒ‰ ì‹œìŠ¤í…œ")
    st.markdown("---")
    
    # API ì´ˆê¸°í™”
    hf_api = init_huggingface_api()
    
    # ì‚¬ì´ë“œë°” ë©”ë‰´
    with st.sidebar:
        st.markdown("## ğŸ“‹ ë©”ë‰´")
        menu = st.radio(
            "ê¸°ëŠ¥ ì„ íƒ:",
            ["ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´", "ğŸ” íŒë¡€ ê²€ìƒ‰", "ğŸ›ï¸ ë²•ë ¹ ê²€ìƒ‰", "ğŸ“ˆ ì‚¬ë¡€ ë¶„ì„"],
            index=0
        )
        
        st.markdown("---")
        st.markdown("### ğŸ”— ë§í¬")
        st.markdown("[ğŸ“Š ë°ì´í„°ì…‹](https://huggingface.co/datasets/LuminaMotionAI/korean-legal-dataset)")
        st.markdown("[âš–ï¸ GitHub](https://github.com/LuminaMotionAI/law-match-agent)")
    
    # ë©”ë‰´ë³„ ê¸°ëŠ¥
    if menu == "ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´":
        st.header("ğŸ“Š ë°ì´í„°ì…‹ ì •ë³´")
        show_dataset_info(hf_api)
        
    elif menu == "ğŸ” íŒë¡€ ê²€ìƒ‰":
        search_legal_cases(hf_api)
        
    elif menu == "ğŸ›ï¸ ë²•ë ¹ ê²€ìƒ‰":
        st.header("ğŸ›ï¸ ë²•ë ¹ ê²€ìƒ‰")
        if hf_api:
            st.info("ğŸ” ë²•ë ¹ ê²€ìƒ‰ ê¸°ëŠ¥ ì¤€ë¹„ ì¤‘...")
        else:
            st.error("âŒ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    elif menu == "ğŸ“ˆ ì‚¬ë¡€ ë¶„ì„":
        st.header("ğŸ“ˆ ì‚¬ë¡€ ë¶„ì„")
        if hf_api:
            st.info("ğŸ“Š ì‚¬ë¡€ ë¶„ì„ ê¸°ëŠ¥ ì¤€ë¹„ ì¤‘...")
        else:
            st.error("âŒ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("ğŸ¤– **Powered by** [Hugging Face](https://huggingface.co/) | "
               "âš–ï¸ **Korean Legal AI** | "
               "ğŸ¢ **LuminaMotionAI**")

if __name__ == "__main__":
    main() 